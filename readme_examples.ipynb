{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook implementation\n",
    "\n",
    "First read the [README](README.md) file if you're new.\n",
    "\n",
    "This is an example of using the code from Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Tree\n",
    "\n",
    "- `Pointnet_Pointnet2_pytorch/`\n",
    "  - `data/`: Data directory, create this manually.\n",
    "    - `modelnet40_normal_resampled/*`: ModelNet40 dataset.\n",
    "    - `shapenetcore_partanno_segmentation_benchmark_v0_normal/*`: ShapeNet dataset.\n",
    "    - `Stanford3dDataset_v1.2_Aligned_Version/*`: S3DIS dataset (unavailable).\n",
    "  - `data_utils/*`: Data Loader.\n",
    "  - `models/*`: Model file, `torch.nn.Module` classes. See below for more details.\n",
    "  - `log/*`: log and output of trained model.\n",
    "  - `visualize/*`: Visualization code. This is independent of the main code.\n",
    "  - `test_*.py`: Predeiction codes.\n",
    "  - `train_*.py`: Training codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "When running `main()`, the argument `--model` will specify the model to be used.\n",
    "It will search the directory `models/` for a file name that matches the argument.\n",
    "Create a new file in the `models/` directory to add a new model.\n",
    "\n",
    "### Aliases\n",
    "\n",
    "Core Model\n",
    "\n",
    "- `pointnet_*.py`: PointNet model\n",
    "- `pointnet2_*.py`: PointNet++ model\n",
    "\n",
    "Task Type\n",
    "\n",
    "- `*_cls*.py`: Classification model\n",
    "- `*_sem_seg*.py`: Segmentation model\n",
    "- `*_part_seg*.py`: Part segmentation model\n",
    "\n",
    "Grouping Method\n",
    "\n",
    "- `*_msg.py`: Multi-scale grouping model\n",
    "- `*_ssg.py`: Single-scale grouping model\n",
    "\n",
    "### Model Directory Tree\n",
    "\n",
    "- `Pointnet_Pointnet2_pytorch/models/`\n",
    "  - `pointnet_cls.py`: PointNet classification model\n",
    "  - `pointnet_part_seg.py`: PointNet part segmentation model\n",
    "  - `pointnet_sem_seg.py`: PointNet semantic segmentation model\n",
    "  - `pointnet_utils.py`: PointNet util functions\n",
    "  - `pointnet2_cls_msg.py`: PointNet++ classification model with multi-scale grouping\n",
    "  - `pointnet2_cls_ssg.py`: PointNet++ classification model with single-scale grouping\n",
    "  - `pointnet2_part_seg_msg.py`: PointNet++ part segmentation model with multi-scale grouping\n",
    "  - `pointnet2_part_seg_ssg.py`: PointNet++ part segmentation model with single-scale grouping\n",
    "  - `pointnet2_sem_seg_msg.py`: PointNet++ semantic segmentation model with multi-scale grouping\n",
    "  - `pointnet2_sem_seg_ssg.py`: PointNet++ semantic segmentation model with single-scale grouping\n",
    "  - `pointnet2_utils.py`: PointNet++ util functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import train_classification\n",
    "import test_classification\n",
    "\n",
    "import train_partseg\n",
    "import test_partseg\n",
    "\n",
    "import train_semseg\n",
    "import test_semseg\n",
    "\n",
    "# import torch\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 16 16:51:49 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.70                 Driver Version: 560.70         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   42C    P8              7W /  220W |    6578MiB /  12282MiB |     14%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      4996    C+G   C:\\Windows\\System32\\Taskmgr.exe             N/A      |\n",
      "|    0   N/A  N/A      8892    C+G   ...es\\Firefox Package Root\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A      9828    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     10276    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     10300    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13544    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14600    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14724    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     15368    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     16720    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16920    C+G   ...e Stream\\94.0.1.0\\GoogleDriveFS.exe      N/A      |\n",
      "|    0   N/A  N/A     17536    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     17728    C+G   ...es\\Firefox Package Root\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A     18116    C+G   ...ogram Files\\Notepad++\\notepad++.exe      N/A      |\n",
      "|    0   N/A  N/A     18540    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     18944    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     21992    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A     23500    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     23752      C   ...0_x64__qbz5n2kfra8p0\\python3.11.exe      N/A      |\n",
      "|    0   N/A  N/A     24028    C+G   ...n\\127.0.2651.105\\msedgewebview2.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Classification (ModelNet)\n",
    "\n",
    "- ModelNet40 dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "#### **INPUT**\n",
    "\n",
    "Default `--data_dir` is `'data/modelnet40_normal_resampled'`.\n",
    "\n",
    "\n",
    "#### **OUTPUT**\n",
    "\n",
    "- TRAINING: `<log_root>/classification/<args.log_dir or TIME>/checkpoints/best_model.pth`\n",
    "- PREDICTION: `None (only prints accuracy)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_classification.py` is used to train the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: training [-h] [--use_cpu] [--gpu GPU] [--batch_size BATCH_SIZE]\n",
      "                [--model MODEL] [--num_category {10,40}] [--epoch EPOCH]\n",
      "                [--learning_rate LEARNING_RATE] [--num_point NUM_POINT]\n",
      "                [--optimizer OPTIMIZER] [--log_root LOG_ROOT]\n",
      "                [--log_dir LOG_DIR] [--decay_rate DECAY_RATE] [--use_normals]\n",
      "                [--process_data] [--use_uniform_sample] [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --use_cpu             use cpu mode\n",
      "  --gpu GPU             specify gpu device\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size in training\n",
      "  --model MODEL         model name [default: pointnet_cls]\n",
      "  --num_category {10,40}\n",
      "                        training on ModelNet10/40\n",
      "  --epoch EPOCH         number of epoch in training\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        learning rate in training\n",
      "  --num_point NUM_POINT\n",
      "                        Point Number\n",
      "  --optimizer OPTIMIZER\n",
      "                        optimizer for training\n",
      "  --log_root LOG_ROOT   log directory root\n",
      "  --log_dir LOG_DIR     experiment root within log directory\n",
      "  --decay_rate DECAY_RATE\n",
      "                        decay rate\n",
      "  --use_normals         use normals\n",
      "  --process_data        save data offline\n",
      "  --use_uniform_sample  use uniform sampiling\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python train_classification.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python train_classification.py --model pointnet2_cls_ssg --log_dir pointnet2_cls_ssg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user defined arguments for command line as a dictionary\n",
    "args = {\n",
    "    'model'   : 'pointnet2_cls_ssg',\n",
    "    'log_dir' : 'pointnet2_cls_ssg'\n",
    "}\n",
    "classification_train_args = train_classification.CommandLineArgs(**args)\n",
    "train_classification.main(classification_train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "`test_classification.py` is used to test the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Testing [-h] [--use_cpu] [--gpu GPU] [--batch_size BATCH_SIZE]\n",
      "               [--num_category {10,40}] [--num_point NUM_POINT]\n",
      "               [--log_root LOG_ROOT] --log_dir LOG_DIR [--use_normals]\n",
      "               [--use_uniform_sample] [--num_votes NUM_VOTES]\n",
      "               [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --use_cpu             use cpu mode\n",
      "  --gpu GPU             specify gpu device\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size in training\n",
      "  --num_category {10,40}\n",
      "                        training on ModelNet10/40\n",
      "  --num_point NUM_POINT\n",
      "                        Point Number\n",
      "  --log_root LOG_ROOT   Log directory root\n",
      "  --log_dir LOG_DIR     Experiment root within log directory\n",
      "  --use_normals         use normals\n",
      "  --use_uniform_sample  use uniform sampiling\n",
      "  --num_votes NUM_VOTES\n",
      "                        Aggregate classification scores with voting\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python test_classification.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python test_classification.py --log_dir pointnet2_cls_ssg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ...\n",
      "CommandLineArgs(log_dir='pointnet2_cls_ssg', use_cpu=False, gpu='0', batch_size=24, num_category=40, num_point=1024, log_root='log', use_normals=False, use_uniform_sample=False, num_votes=3, data_dir='data/modelnet40_normal_resampled')\n",
      "Load dataset ...\n",
      "The size of test data is 2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [01:02<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Instance Accuracy: 0.921197, Class Accuracy: 0.893315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"log_dir\": \"pointnet2_cls_ssg\",\n",
    "}\n",
    "classification_test_args = test_classification.CommandLineArgs(**args)\n",
    "test_classification.main(classification_test_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part Segmentation (ShapeNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "#### **INPUT**\n",
    "\n",
    "Default `--data_dir` is `'data/shapenetcore_partanno_segmentation_benchmark_v0_normal'`.\n",
    "\n",
    "From `data/shapenetcore_partanno_segmentation_benchmark_v0_normal/synsetoffset2category.txt`, the folders correspond to the following categories:\n",
    "\n",
    "- `Airplane`: 02691156\n",
    "- `Bag`: 02773838\n",
    "- `Cap`: 02954340\n",
    "- `Car`: 02958343\n",
    "- `Chair`: 03001627\n",
    "- `Earphone`: 03261776\n",
    "- `Guitar`: 03467517\n",
    "- `Knife`: 03624134\n",
    "- `Lamp`: 03636649\n",
    "- `Laptop`: 03642806\n",
    "- `Motorbike`: 03790512\n",
    "- `Mug`: 03797390\n",
    "- `Pistol`: 03948459\n",
    "- `Rocket`: 04099429\n",
    "- `Skateboard`: 04225987\n",
    "- `Table`: 04379243\n",
    "\n",
    "For each .txt file within the folder above, \n",
    "\n",
    " - `[i, :]` is the i th point.\n",
    " - `[:, 0:3]` is xyz.\n",
    " - `[:, 3:6]` is normalized xyz.\n",
    " - `[:, 6]` is the segmentation label.\n",
    "\n",
    "i.e., each row is a point, and the columns are `[x, y, z, nx, ny, nz, label]`.\n",
    "\n",
    "`--normal` flag will use all x-y-z-nx-ny-nz + label as input. Otherwise, only x-y-z + label will be used.\n",
    "\n",
    "#### **OUTPUT**\n",
    "\n",
    "- TRAINING: `<log_root>/part_seg/<args.log_dir or TIME>/checkpoints/best_model.pth`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Segmentation Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shapenet part segmentation\n",
    "seg_classes = {\n",
    "    'Earphone': [16, 17, 18],\n",
    "    'Motorbike': [30, 31, 32, 33, 34, 35],\n",
    "    'Rocket': [41, 42, 43],\n",
    "    'Car': [8, 9, 10, 11],\n",
    "    'Laptop': [28, 29],\n",
    "    'Cap': [6, 7],\n",
    "    'Skateboard': [44, 45, 46],\n",
    "    'Mug': [36, 37],\n",
    "    'Guitar': [19, 20, 21],\n",
    "    'Bag': [4, 5],\n",
    "    'Lamp': [24, 25, 26, 27],\n",
    "    'Table': [47, 48, 49],\n",
    "    'Airplane': [0, 1, 2, 3],\n",
    "    'Pistol': [38, 39, 40],\n",
    "    'Chair': [12, 13, 14, 15],\n",
    "    'Knife': [22, 23]\n",
    "}\n",
    "\n",
    "seg_ids = [seg_id for seg_val_sublist in seg_classes.values() for seg_id in seg_val_sublist]\n",
    "len(seg_classes), len(seg_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "`train_partseg.py` is used to train the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Model [-h] [--model MODEL] [--batch_size BATCH_SIZE] [--epoch EPOCH]\n",
      "             [--learning_rate LEARNING_RATE] [--gpu GPU]\n",
      "             [--optimizer OPTIMIZER] [--log_root LOG_ROOT] [--log_dir LOG_DIR]\n",
      "             [--decay_rate DECAY_RATE] [--npoint NPOINT] [--normal]\n",
      "             [--step_size STEP_SIZE] [--lr_decay LR_DECAY]\n",
      "             [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model MODEL         model name\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch Size during training\n",
      "  --epoch EPOCH         epoch to run\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        initial learning rate\n",
      "  --gpu GPU             specify GPU devices\n",
      "  --optimizer OPTIMIZER\n",
      "                        Adam or SGD\n",
      "  --log_root LOG_ROOT   Log root directory\n",
      "  --log_dir LOG_DIR     log path wihin log root directory\n",
      "  --decay_rate DECAY_RATE\n",
      "                        weight decay\n",
      "  --npoint NPOINT       point Number\n",
      "  --normal              use normals\n",
      "  --step_size STEP_SIZE\n",
      "                        decay step for lr decay\n",
      "  --lr_decay LR_DECAY   decay rate for lr decay\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python train_partseg.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python train_partseg.py --model pointnet2_part_seg_msg --normal --log_dir pointnet2_part_seg_msg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ...\n",
      "CommandLineArgs(model='pointnet2_part_seg_msg', normal=True, log_dir='pointnet2_part_seg_msg', batch_size=16, epoch=251, learning_rate=0.001, gpu='0', optimizer='Adam', log_root='log', decay_rate=0.0001, npoint=2048, step_size=20, lr_decay=0.5, data_dir='data/shapenetcore_partanno_segmentation_benchmark_v0_normal')\n",
      "The number of training data is: 13998\n",
      "The number of test data is: 2874\n",
      "Use pretrain model\n",
      "Epoch 1 (115/251):\n",
      "Learning rate:0.000031\n",
      "BN momentum updated to: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 874/874 [05:12<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is: 0.95623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:48<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mIoU of Airplane       0.827037\n",
      "eval mIoU of Bag            0.805515\n",
      "eval mIoU of Cap            0.845203\n",
      "eval mIoU of Car            0.779159\n",
      "eval mIoU of Chair          0.907756\n",
      "eval mIoU of Earphone       0.681023\n",
      "eval mIoU of Guitar         0.912425\n",
      "eval mIoU of Knife          0.871786\n",
      "eval mIoU of Lamp           0.844128\n",
      "eval mIoU of Laptop         0.953616\n",
      "eval mIoU of Motorbike      0.721992\n",
      "eval mIoU of Mug            0.949424\n",
      "eval mIoU of Pistol         0.810817\n",
      "eval mIoU of Rocket         0.608141\n",
      "eval mIoU of Skateboard     0.758713\n",
      "eval mIoU of Table          0.827735\n",
      "Epoch 115 test Accuracy: 0.944043  Class avg mIOU: 0.819029   Inctance avg mIOU: 0.852818\n",
      "Saving at log\\part_seg\\pointnet2_part_seg_msg\\checkpoints/best_model.pth\n",
      "Saving model....\n",
      "Best accuracy is: 0.94404\n",
      "Best class avg mIOU is: 0.81903\n",
      "Best inctance avg mIOU is: 0.85282\n",
      "Epoch 2 (116/251):\n",
      "Learning rate:0.000031\n",
      "BN momentum updated to: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 874/874 [05:22<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is: 0.95638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 58/180 [00:25<00:52,  2.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m   : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpointnet2_part_seg_msg\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m  : \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# in source: action='store_true'\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_dir\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpointnet2_part_seg_msg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m }\n\u001b[0;32m      6\u001b[0m partseg_train_args \u001b[38;5;241m=\u001b[39m train_partseg\u001b[38;5;241m.\u001b[39mCommandLineArgs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrain_partseg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartseg_train_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_classes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\Documents\\pointnet-cleanup\\Pointnet_Pointnet2_pytorch\\train_partseg.py:260\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args, seg_classes)\u001b[0m\n\u001b[0;32m    258\u001b[0m     cat \u001b[38;5;241m=\u001b[39m seg_label_to_cat[target[i, \u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    259\u001b[0m     logits \u001b[38;5;241m=\u001b[39m cur_pred_val_logits[i, :, :]\n\u001b[1;32m--> 260\u001b[0m     cur_pred_val[i, :] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(logits[:, seg_classes[cat]], \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m seg_classes[cat][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    262\u001b[0m correct \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(cur_pred_val \u001b[38;5;241m==\u001b[39m target)\n\u001b[0;32m    263\u001b[0m total_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m correct\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\.virtualenvs\\paprika311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\.virtualenvs\\paprika311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\Documents\\pointnet-cleanup\\Pointnet_Pointnet2_pytorch\\models\\pointnet2_part_seg_msg.py:35\u001b[0m, in \u001b[0;36mget_model.forward\u001b[1;34m(self, xyz, cls_label)\u001b[0m\n\u001b[0;32m     33\u001b[0m     l0_points \u001b[38;5;241m=\u001b[39m xyz\n\u001b[0;32m     34\u001b[0m     l0_xyz \u001b[38;5;241m=\u001b[39m xyz\n\u001b[1;32m---> 35\u001b[0m l1_xyz, l1_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msa1\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml0_xyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml0_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m l2_xyz, l2_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa2(l1_xyz, l1_points)\n\u001b[0;32m     37\u001b[0m l3_xyz, l3_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa3(l2_xyz, l2_points)\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\.virtualenvs\\paprika311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\.virtualenvs\\paprika311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\Documents\\pointnet-cleanup\\Pointnet_Pointnet2_pytorch\\models\\pointnet2_utils.py:244\u001b[0m, in \u001b[0;36mPointNetSetAbstractionMsg.forward\u001b[1;34m(self, xyz, points)\u001b[0m\n\u001b[0;32m    242\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsample_list[i]\n\u001b[0;32m    243\u001b[0m group_idx \u001b[38;5;241m=\u001b[39m query_ball_point(radius, K, xyz, new_xyz)\n\u001b[1;32m--> 244\u001b[0m grouped_xyz \u001b[38;5;241m=\u001b[39m \u001b[43mindex_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m grouped_xyz \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m new_xyz\u001b[38;5;241m.\u001b[39mview(B, S, \u001b[38;5;241m1\u001b[39m, C)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\Documents\\pointnet-cleanup\\Pointnet_Pointnet2_pytorch\\models\\pointnet2_utils.py:43\u001b[0m, in \u001b[0;36mindex_points\u001b[1;34m(points, idx)\u001b[0m\n\u001b[0;32m     39\u001b[0m     dist \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(dst \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(B, \u001b[38;5;241m1\u001b[39m, M)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dist\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindex_points\u001b[39m(points, idx):\n\u001b[0;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    Input:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m        new_points:, indexed points data, [B, S, C]\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     device \u001b[38;5;241m=\u001b[39m points\u001b[38;5;241m.\u001b[39mdevice\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'model'   : 'pointnet2_part_seg_msg',\n",
    "    'normal'  : True, # in source: action='store_true'\n",
    "    'log_dir' : 'pointnet2_part_seg_msg'\n",
    "}\n",
    "partseg_train_args = train_partseg.CommandLineArgs(**args)\n",
    "train_partseg.main(partseg_train_args, seg_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "`test_partseg.py` is used to test the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: PointNet [-h] [--batch_size BATCH_SIZE] [--gpu GPU]\n",
      "                [--num_point NUM_POINT] [--log_root LOG_ROOT] --log_dir\n",
      "                LOG_DIR [--normal] [--num_votes NUM_VOTES]\n",
      "                [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size in testing\n",
      "  --gpu GPU             specify gpu device\n",
      "  --num_point NUM_POINT\n",
      "                        point Number\n",
      "  --log_root LOG_ROOT   Log directory root\n",
      "  --log_dir LOG_DIR     experiment root within log directory\n",
      "  --normal              use normals\n",
      "  --num_votes NUM_VOTES\n",
      "                        aggregate segmentation scores with voting\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python test_partseg.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python test_partseg.py --normal --log_dir pointnet2_part_seg_msg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ...\n",
      "CommandLineArgs(normal=True, log_dir='pointnet2_part_seg_msg', batch_size=24, gpu='0', num_point=2048, log_root='log', num_votes=3, data_dir='data/shapenetcore_partanno_segmentation_benchmark_v0_normal')\n",
      "The number of test data is: 2874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [01:57<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mIoU of Airplane       0.827793\n",
      "eval mIoU of Bag            0.819054\n",
      "eval mIoU of Cap            0.847410\n",
      "eval mIoU of Car            0.787049\n",
      "eval mIoU of Chair          0.907639\n",
      "eval mIoU of Earphone       0.677332\n",
      "eval mIoU of Guitar         0.909006\n",
      "eval mIoU of Knife          0.878172\n",
      "eval mIoU of Lamp           0.845606\n",
      "eval mIoU of Laptop         0.954710\n",
      "eval mIoU of Motorbike      0.730167\n",
      "eval mIoU of Mug            0.936857\n",
      "eval mIoU of Pistol         0.809644\n",
      "eval mIoU of Rocket         0.619508\n",
      "eval mIoU of Skateboard     0.765547\n",
      "eval mIoU of Table          0.827636\n",
      "Accuracy is: 0.94422\n",
      "Class avg accuracy is: 0.87388\n",
      "Class avg mIOU is: 0.82145\n",
      "Inctance avg mIOU is: 0.85359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'normal'  : True, # in source: action='store_true'\n",
    "    'log_dir' : 'pointnet2_part_seg_msg'\n",
    "}\n",
    "partseg_test_args = test_partseg.CommandLineArgs(**args)\n",
    "test_metrics, shape_ious, total_correct_class, total_seen_class = test_partseg.main(partseg_test_args, seg_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.944217689848643,\n",
       "  'class_avg_accuracy': 0.873883348292801,\n",
       "  'class_avg_iou': 0.8214457956595069,\n",
       "  'inctance_avg_iou': 0.8535893073448165},\n",
       " {'Earphone': 0.6773323450366551,\n",
       "  'Motorbike': 0.7301673399559926,\n",
       "  'Rocket': 0.6195077200752838,\n",
       "  'Car': 0.7870494489288018,\n",
       "  'Laptop': 0.954710148860332,\n",
       "  'Cap': 0.8474099793990699,\n",
       "  'Skateboard': 0.765547128553441,\n",
       "  'Mug': 0.9368570695110039,\n",
       "  'Guitar': 0.9090064091237873,\n",
       "  'Bag': 0.819053833290052,\n",
       "  'Lamp': 0.845606487924264,\n",
       "  'Table': 0.8276362923798146,\n",
       "  'Airplane': 0.8277933496179767,\n",
       "  'Pistol': 0.8096440630883308,\n",
       "  'Chair': 0.9076394718467004,\n",
       "  'Knife': 0.8781716429606062})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics, shape_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Airplane': {0: 0.9556782288678316,\n",
      "              1: 0.9046608061038315,\n",
      "              2: 0.8333405795526184,\n",
      "              3: 0.8890591114382921},\n",
      " 'Bag': {4: 0.6414209115281502, 5: 0.9971971348489567},\n",
      " 'Cap': {6: 0.9960916361012567, 7: 0.7022214685433271},\n",
      " 'Car': {8: 0.876130252349152,\n",
      "         9: 0.7970049192460058,\n",
      "         10: 0.879316992564032,\n",
      "         11: 0.9497528650638887},\n",
      " 'Chair': {12: 0.9605425400739828,\n",
      "           13: 0.9629423585839048,\n",
      "           14: 0.9317548790056613,\n",
      "           15: 0.8386358300070439},\n",
      " 'Earphone': {16: 0.9494058065486637,\n",
      "              17: 0.9506273867975996,\n",
      "              18: 0.297780959198282},\n",
      " 'Guitar': {19: 0.9550621025928244,\n",
      "            20: 0.9023781942078365,\n",
      "            21: 0.9868276371764366},\n",
      " 'Knife': {22: 0.9095146156400261, 23: 0.9651248742774742},\n",
      " 'Lamp': {24: 0.9179840099322509,\n",
      "          25: 0.9600608025499956,\n",
      "          26: 0.9450210378681627,\n",
      "          27: 0.815333563541728},\n",
      " 'Laptop': {28: 0.980030937983406, 29: 0.9784759030706336},\n",
      " 'Motorbike': {30: 0.8549704308645452,\n",
      "               31: 0.7981765437215085,\n",
      "               32: 0.8422600199040985,\n",
      "               33: 0.7504930966469427,\n",
      "               34: 0.7525967894239849,\n",
      "               35: 0.8982389688215507},\n",
      " 'Mug': {36: 0.9246641074856046, 37: 0.9985608775931356},\n",
      " 'Pistol': {38: 0.9854376001164992,\n",
      "            39: 0.9256874126170402,\n",
      "            40: 0.7110072248193795},\n",
      " 'Rocket': {41: 0.9375260060631279,\n",
      "            42: 0.6258309591642925,\n",
      "            43: 0.7069935691318328},\n",
      " 'Skateboard': {44: 0.8617608409986859,\n",
      "                45: 0.9827530472151971,\n",
      "                46: 0.8127090301003345},\n",
      " 'Table': {47: 0.9822500408318815,\n",
      "           48: 0.9403155404911117,\n",
      "           49: 0.7725569633660352}}\n"
     ]
    }
   ],
   "source": [
    "seg_correct = dict(zip(range(len(seg_ids)), total_correct_class))\n",
    "seg_total = dict(zip(range(len(seg_ids)), total_seen_class))\n",
    "\n",
    "seg_acc = {}\n",
    "for id, correct_n in seg_correct.items():\n",
    "    total_n = seg_total[id]\n",
    "    if total_n == 0:\n",
    "        seg_acc[id] = 0\n",
    "    else:\n",
    "        seg_acc[id] = correct_n / total_n\n",
    "# print(seg_acc)\n",
    "\n",
    "seg_class_acc = {}\n",
    "for cat in seg_classes:\n",
    "    seg_class_acc[cat] = {}\n",
    "    for id in seg_classes[cat]:\n",
    "        seg_class_acc[cat][id] = seg_acc[id]\n",
    "\n",
    "pprint(seg_class_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Semantic Segmentation (S3DIS): **UNTESTED**\n",
    "\n",
    "**UNTESTED**: Unfortunately, the S3DIS dataset is not available as of Aug. 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "`train_semseg.py` is used to train the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Model [-h] [--model MODEL] [--batch_size BATCH_SIZE] [--epoch EPOCH]\n",
      "             [--learning_rate LEARNING_RATE] [--gpu GPU]\n",
      "             [--optimizer OPTIMIZER] [--log_dir LOG_DIR]\n",
      "             [--decay_rate DECAY_RATE] [--npoint NPOINT]\n",
      "             [--step_size STEP_SIZE] [--lr_decay LR_DECAY]\n",
      "             [--test_area TEST_AREA] [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model MODEL         model name [default: pointnet_sem_seg]\n",
      "  --batch_size BATCH_SIZE\n",
      "                        Batch Size during training [default: 16]\n",
      "  --epoch EPOCH         Epoch to run [default: 32]\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        Initial learning rate [default: 0.001]\n",
      "  --gpu GPU             GPU to use [default: GPU 0]\n",
      "  --optimizer OPTIMIZER\n",
      "                        Adam or SGD [default: Adam]\n",
      "  --log_dir LOG_DIR     Log path [default: None]\n",
      "  --decay_rate DECAY_RATE\n",
      "                        weight decay [default: 1e-4]\n",
      "  --npoint NPOINT       Point Number [default: 4096]\n",
      "  --step_size STEP_SIZE\n",
      "                        Decay step for lr decay [default: every 10 epochs]\n",
      "  --lr_decay LR_DECAY   Decay rate for lr decay [default: 0.7]\n",
      "  --test_area TEST_AREA\n",
      "                        Which area to use for test, option: 1-6 [default: 5]\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python train_semseg.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python train_semseg.py --model pointnet2_sem_seg --test_area 5 --log_dir pointnet2_sem_seg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'model'    : 'pointnet2_sem_seg',\n",
    "    'test_area': 5,\n",
    "    'log_dir'  : 'pointnet2_sem_seg'\n",
    "}\n",
    "semseg_train_args = train_semseg.CommandLineArgs(**args)\n",
    "train_semseg.main(semseg_train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "`test_semseg.py` is used to test the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Model [-h] [--batch_size BATCH_SIZE] [--gpu GPU]\n",
      "             [--num_point NUM_POINT] --log_dir LOG_DIR [--visual]\n",
      "             [--test_area TEST_AREA] [--num_votes NUM_VOTES]\n",
      "             [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size in testing [default: 32]\n",
      "  --gpu GPU             specify gpu device\n",
      "  --num_point NUM_POINT\n",
      "                        point number [default: 4096]\n",
      "  --log_dir LOG_DIR     experiment root\n",
      "  --visual              visualize result [default: False]\n",
      "  --test_area TEST_AREA\n",
      "                        area for testing, option: 1-6 [default: 5]\n",
      "  --num_votes NUM_VOTES\n",
      "                        aggregate segmentation scores with voting [default: 5]\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python test_semseg.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python test_semseg.py --log_dir pointnet2_sem_seg --test_area 5 --visual\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'log_dir'  : 'pointnet2_sem_seg',\n",
    "    'test_area': 5,\n",
    "    'visual'   : True, # in source: action='store_true'\n",
    "}\n",
    "semseg_test_args = test_semseg.CommandLineArgs(**args)\n",
    "test_semseg.main(semseg_test_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paprika311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
