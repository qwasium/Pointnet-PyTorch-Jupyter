{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook implementation\n",
    "\n",
    "First read the [README](README.md) file if you're new.\n",
    "\n",
    "This is an example of using the code from Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Tree\n",
    "\n",
    "- `Pointnet_Pointnet2_pytorch/`\n",
    "  - `data/*`: Data directory, create this manually.\n",
    "  - `data_utils/*`: Data Loader.\n",
    "  - `models/*`: Model file, `torch.nn.Module` classes. See below for more details.\n",
    "  - `log/*`: log and output directory.\n",
    "  - `visualize/*`: Visualization code. This is independent of the main code.\n",
    "  - `test_*.py`: Predeiction codes.\n",
    "  - `train_*.py`: Training codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "When running `main()`, the argument `--model` will specify the model to be used.\n",
    "It will search the directory `models/` for a file name that matches the argument.\n",
    "Create a new file in the `models/` directory to add a new model.\n",
    "\n",
    "### Aliases\n",
    "\n",
    "Core Model\n",
    "\n",
    "- `pointnet_*.py`: PointNet model\n",
    "- `pointnet2_*.py`: PointNet++ model\n",
    "\n",
    "Task Type\n",
    "\n",
    "- `*_cls*.py`: Classification model\n",
    "- `*_sem_seg*.py`: Segmentation model\n",
    "- `*_part_seg*.py`: Part segmentation model\n",
    "\n",
    "Grouping Method\n",
    "\n",
    "- `*_msg.py`: Multi-scale grouping model\n",
    "- `*_ssg.py`: Single-scale grouping model\n",
    "\n",
    "### Model Directory Tree\n",
    "\n",
    "- `models`\n",
    "  - `pointnet_cls.py`: PointNet classification model\n",
    "  - `pointnet_part_seg.py`: PointNet part segmentation model\n",
    "  - `pointnet_sem_seg.py`: PointNet semantic segmentation model\n",
    "  - `pointnet_utils.py`: PointNet util functions\n",
    "  - `pointnet2_cls_msg.py`: PointNet++ classification model with multi-scale grouping\n",
    "  - `pointnet2_cls_ssg.py`: PointNet++ classification model with single-scale grouping\n",
    "  - `pointnet2_part_seg_msg.py`: PointNet++ part segmentation model with multi-scale grouping\n",
    "  - `pointnet2_part_seg_ssg.py`: PointNet++ part segmentation model with single-scale grouping\n",
    "  - `pointnet2_sem_seg_msg.py`: PointNet++ semantic segmentation model with multi-scale grouping\n",
    "  - `pointnet2_sem_seg_ssg.py`: PointNet++ semantic segmentation model with single-scale grouping\n",
    "  - `pointnet2_utils.py`: PointNet++ util functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import train_classification\n",
    "import test_classification\n",
    "\n",
    "import train_partseg\n",
    "import test_partseg\n",
    "\n",
    "import train_semseg\n",
    "import test_semseg\n",
    "\n",
    "# import torch\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 14 13:48:45 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.70                 Driver Version: 560.70         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   41C    P8              8W /  220W |    2053MiB /  12282MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2332    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A      8860    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     11696    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     12692    C+G   ...on\\127.0.2651.98\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     13044    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13612    C+G   ...on\\127.0.2651.86\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     14520    C+G   ...42.0_x64__8wekyb3d8bbwe\\GameBar.exe      N/A      |\n",
      "|    0   N/A  N/A     15188    C+G   ...757_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A     16672    C+G   ...s\\MZLA Package Root\\thunderbird.exe      N/A      |\n",
      "|    0   N/A  N/A     18016    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     18376    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     18428    C+G   C:\\Windows\\System32\\Taskmgr.exe             N/A      |\n",
      "|    0   N/A  N/A     19004    C+G   ...ogram Files\\Notepad++\\notepad++.exe      N/A      |\n",
      "|    0   N/A  N/A     19544    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     19732    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     22460    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     23900    C+G   ...es\\Firefox Package Root\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A     24248    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     25928    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     26264    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     26436    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     26836    C+G   ...e Stream\\94.0.1.0\\GoogleDriveFS.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Classification (ModelNet)\n",
    "\n",
    "- ModelNet40 dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "#### **INPUT**\n",
    "\n",
    "Default `--data_dir` is `'data/modelnet40_normal_resampled'`.\n",
    "\n",
    "\n",
    "#### **OUTPUT**\n",
    "\n",
    "- TRAINING: `log/classification/<args.log_dir or TIME>/checkpoints/best_model.pth`\n",
    "- PREDICTION: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_classification.py` is used to train the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: training [-h] [--use_cpu] [--gpu GPU] [--batch_size BATCH_SIZE]\n",
      "                [--model MODEL] [--num_category {10,40}] [--epoch EPOCH]\n",
      "                [--learning_rate LEARNING_RATE] [--num_point NUM_POINT]\n",
      "                [--optimizer OPTIMIZER] [--log_dir LOG_DIR]\n",
      "                [--decay_rate DECAY_RATE] [--use_normals] [--process_data]\n",
      "                [--use_uniform_sample] [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --use_cpu             use cpu mode\n",
      "  --gpu GPU             specify gpu device\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size in training\n",
      "  --model MODEL         model name [default: pointnet_cls]\n",
      "  --num_category {10,40}\n",
      "                        training on ModelNet10/40\n",
      "  --epoch EPOCH         number of epoch in training\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        learning rate in training\n",
      "  --num_point NUM_POINT\n",
      "                        Point Number\n",
      "  --optimizer OPTIMIZER\n",
      "                        optimizer for training\n",
      "  --log_dir LOG_DIR     experiment root\n",
      "  --decay_rate DECAY_RATE\n",
      "                        decay rate\n",
      "  --use_normals         use normals\n",
      "  --process_data        save data offline\n",
      "  --use_uniform_sample  use uniform sampiling\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python train_classification.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python train_classification.py --model pointnet2_cls_ssg --log_dir pointnet2_cls_ssg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ...\n",
      "CommandLineArgs(model='pointnet2_cls_ssg', log_dir='pointnet2_cls_ssg', use_cpu=False, gpu='0', batch_size=25, num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='adam', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False, data_dir='data/modelnet40_normal_resampled')\n",
      "Load dataset ...\n",
      "The size of train data is 9843\n",
      "The size of test data is 2468\n",
      "No existing model, starting training from scratch...\n",
      "Epoch 1 (1/200):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 22/393 [00:07<02:09,  2.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m   : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpointnet2_cls_ssg\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_dir\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpointnet2_cls_ssg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m }\n\u001b[0;32m      6\u001b[0m classification_train_args \u001b[38;5;241m=\u001b[39m train_classification\u001b[38;5;241m.\u001b[39mCommandLineArgs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrain_classification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassification_train_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\Documents\\pointnet-cleanup\\Pointnet_Pointnet2_pytorch\\train_classification.py:218\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    215\u001b[0m points \u001b[38;5;241m=\u001b[39m points\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39muse_cpu:\n\u001b[1;32m--> 218\u001b[0m     points, target \u001b[38;5;241m=\u001b[39m \u001b[43mpoints\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, target\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m    220\u001b[0m pred, trans_feat \u001b[38;5;241m=\u001b[39m classifier(points)\n\u001b[0;32m    221\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred, target\u001b[38;5;241m.\u001b[39mlong(), trans_feat)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# user defined arguments for command line as a dictionary\n",
    "args = {\n",
    "    'model'   : 'pointnet2_cls_ssg',\n",
    "    'log_dir' : 'pointnet2_cls_ssg'\n",
    "}\n",
    "classification_train_args = train_classification.CommandLineArgs(**args)\n",
    "train_classification.main(classification_train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "`test_classification.py` is used to test the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Testing [-h] [--use_cpu] [--gpu GPU] [--batch_size BATCH_SIZE]\n",
      "               [--num_category {10,40}] [--num_point NUM_POINT] --log_dir\n",
      "               LOG_DIR [--use_normals] [--use_uniform_sample]\n",
      "               [--num_votes NUM_VOTES] [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --use_cpu             use cpu mode\n",
      "  --gpu GPU             specify gpu device\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size in training\n",
      "  --num_category {10,40}\n",
      "                        training on ModelNet10/40\n",
      "  --num_point NUM_POINT\n",
      "                        Point Number\n",
      "  --log_dir LOG_DIR     Experiment root\n",
      "  --use_normals         use normals\n",
      "  --use_uniform_sample  use uniform sampiling\n",
      "  --num_votes NUM_VOTES\n",
      "                        Aggregate classification scores with voting\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python test_classification.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python test_classification.py --log_dir pointnet2_cls_ssg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"log_dir\": \"pointnet2_cls_ssg\",\n",
    "}\n",
    "classification_test_args = test_classification.CommandLineArgs(**args)\n",
    "test_classification.main(classification_test_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part Segmentation (ShapeNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "`train_partseg.py` is used to train the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Model [-h] [--model MODEL] [--batch_size BATCH_SIZE] [--epoch EPOCH]\n",
      "             [--learning_rate LEARNING_RATE] [--gpu GPU]\n",
      "             [--optimizer OPTIMIZER] [--log_dir LOG_DIR]\n",
      "             [--decay_rate DECAY_RATE] [--npoint NPOINT] [--normal]\n",
      "             [--step_size STEP_SIZE] [--lr_decay LR_DECAY]\n",
      "             [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model MODEL         model name\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch Size during training\n",
      "  --epoch EPOCH         epoch to run\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        initial learning rate\n",
      "  --gpu GPU             specify GPU devices\n",
      "  --optimizer OPTIMIZER\n",
      "                        Adam or SGD\n",
      "  --log_dir LOG_DIR     log path\n",
      "  --decay_rate DECAY_RATE\n",
      "                        weight decay\n",
      "  --npoint NPOINT       point Number\n",
      "  --normal              use normals\n",
      "  --step_size STEP_SIZE\n",
      "                        decay step for lr decay\n",
      "  --lr_decay LR_DECAY   decay rate for lr decay\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python train_partseg.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python train_partseg.py --model pointnet2_part_seg_msg --normal --log_dir pointnet2_part_seg_msg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'model'   : 'pointnet2_part_seg_msg',\n",
    "    'normal'  : True, # in source: action='store_true'\n",
    "    'log_dir' : 'pointnet2_part_seg_msg'\n",
    "}\n",
    "partseg_train_args = train_partseg.CommandLineArgs(**args)\n",
    "train_partseg.main(partseg_train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "`test_partseg.py` is used to test the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: PointNet [-h] [--batch_size BATCH_SIZE] [--gpu GPU]\n",
      "                [--num_point NUM_POINT] --log_dir LOG_DIR [--normal]\n",
      "                [--num_votes NUM_VOTES] [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size in testing\n",
      "  --gpu GPU             specify gpu device\n",
      "  --num_point NUM_POINT\n",
      "                        point Number\n",
      "  --log_dir LOG_DIR     experiment root\n",
      "  --normal              use normals\n",
      "  --num_votes NUM_VOTES\n",
      "                        aggregate segmentation scores with voting\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python test_partseg.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python test_partseg.py --normal --log_dir pointnet2_part_seg_msg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'normal'  : True, # in source: action='store_true'\n",
    "    'log_dir' : 'pointnet2_part_seg_msg'\n",
    "}\n",
    "partseg_test_args = test_partseg.CommandLineArgs(**args)\n",
    "test_partseg.main(partseg_test_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Semantic Segmentation (S3DIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "`train_semseg.py` is used to train the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Model [-h] [--model MODEL] [--batch_size BATCH_SIZE] [--epoch EPOCH]\n",
      "             [--learning_rate LEARNING_RATE] [--gpu GPU]\n",
      "             [--optimizer OPTIMIZER] [--log_dir LOG_DIR]\n",
      "             [--decay_rate DECAY_RATE] [--npoint NPOINT]\n",
      "             [--step_size STEP_SIZE] [--lr_decay LR_DECAY]\n",
      "             [--test_area TEST_AREA] [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model MODEL         model name [default: pointnet_sem_seg]\n",
      "  --batch_size BATCH_SIZE\n",
      "                        Batch Size during training [default: 16]\n",
      "  --epoch EPOCH         Epoch to run [default: 32]\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        Initial learning rate [default: 0.001]\n",
      "  --gpu GPU             GPU to use [default: GPU 0]\n",
      "  --optimizer OPTIMIZER\n",
      "                        Adam or SGD [default: Adam]\n",
      "  --log_dir LOG_DIR     Log path [default: None]\n",
      "  --decay_rate DECAY_RATE\n",
      "                        weight decay [default: 1e-4]\n",
      "  --npoint NPOINT       Point Number [default: 4096]\n",
      "  --step_size STEP_SIZE\n",
      "                        Decay step for lr decay [default: every 10 epochs]\n",
      "  --lr_decay LR_DECAY   Decay rate for lr decay [default: 0.7]\n",
      "  --test_area TEST_AREA\n",
      "                        Which area to use for test, option: 1-6 [default: 5]\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python train_semseg.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python train_semseg.py --model pointnet2_sem_seg --test_area 5 --log_dir pointnet2_sem_seg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'model'    : 'pointnet2_sem_seg',\n",
    "    'test_area': 5,\n",
    "    'log_dir'  : 'pointnet2_sem_seg'\n",
    "}\n",
    "semseg_train_args = train_semseg.CommandLineArgs(**args)\n",
    "train_semseg.main(semseg_train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "`test_semseg.py` is used to test the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Model [-h] [--batch_size BATCH_SIZE] [--gpu GPU]\n",
      "             [--num_point NUM_POINT] --log_dir LOG_DIR [--visual]\n",
      "             [--test_area TEST_AREA] [--num_votes NUM_VOTES]\n",
      "             [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size in testing [default: 32]\n",
      "  --gpu GPU             specify gpu device\n",
      "  --num_point NUM_POINT\n",
      "                        point number [default: 4096]\n",
      "  --log_dir LOG_DIR     experiment root\n",
      "  --visual              visualize result [default: False]\n",
      "  --test_area TEST_AREA\n",
      "                        area for testing, option: 1-6 [default: 5]\n",
      "  --num_votes NUM_VOTES\n",
      "                        aggregate segmentation scores with voting [default: 5]\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python test_semseg.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python test_semseg.py --log_dir pointnet2_sem_seg --test_area 5 --visual\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'log_dir'  : 'pointnet2_sem_seg',\n",
    "    'test_area': 5,\n",
    "    'visual'   : True, # in source: action='store_true'\n",
    "}\n",
    "semseg_test_args = test_semseg.CommandLineArgs(**args)\n",
    "test_semseg.main(semseg_test_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paprika311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
