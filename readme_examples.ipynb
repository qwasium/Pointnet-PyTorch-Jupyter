{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook implementation\n",
    "\n",
    "First read the [README](README.md) file if you're new.\n",
    "\n",
    "This is an example of using the code from Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Tree\n",
    "\n",
    "- `Pointnet_Pointnet2_pytorch/`\n",
    "  - `data/`: Data directory, create this manually.\n",
    "    - `modelnet40_normal_resampled/*`: ModelNet40 dataset.\n",
    "    - `shapenetcore_partanno_segmentation_benchmark_v0_normal/*`: ShapeNet dataset.\n",
    "    - `Stanford3dDataset_v1.2_Aligned_Version/*`: S3DIS dataset (unavailable).\n",
    "  - `data_utils/*`: Data Loader.\n",
    "  - `models/*`: Model file, `torch.nn.Module` classes. See below for more details.\n",
    "  - `log/*`: log and output of trained model.\n",
    "  - `visualize/*`: Visualization code. This is independent of the main code.\n",
    "  - `test_*.py`: Predeiction codes.\n",
    "  - `train_*.py`: Training codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "When running `main()`, the argument `--model` will specify the model to be used.\n",
    "It will search the directory `models/` for a file name that matches the argument.\n",
    "Create a new file in the `models/` directory to add a new model.\n",
    "\n",
    "### Aliases\n",
    "\n",
    "Core Model\n",
    "\n",
    "- `pointnet_*.py`: PointNet model\n",
    "- `pointnet2_*.py`: PointNet++ model\n",
    "\n",
    "Task Type\n",
    "\n",
    "- `*_cls*.py`: Classification model\n",
    "- `*_sem_seg*.py`: Segmentation model\n",
    "- `*_part_seg*.py`: Part segmentation model\n",
    "\n",
    "Grouping Method\n",
    "\n",
    "- `*_msg.py`: Multi-scale grouping model\n",
    "- `*_ssg.py`: Single-scale grouping model\n",
    "\n",
    "### Model Directory Tree\n",
    "\n",
    "- `Pointnet_Pointnet2_pytorch/models/`\n",
    "  - `pointnet_cls.py`: PointNet classification model\n",
    "  - `pointnet_part_seg.py`: PointNet part segmentation model\n",
    "  - `pointnet_sem_seg.py`: PointNet semantic segmentation model\n",
    "  - `pointnet_utils.py`: PointNet util functions\n",
    "  - `pointnet2_cls_msg.py`: PointNet++ classification model with multi-scale grouping\n",
    "  - `pointnet2_cls_ssg.py`: PointNet++ classification model with single-scale grouping\n",
    "  - `pointnet2_part_seg_msg.py`: PointNet++ part segmentation model with multi-scale grouping\n",
    "  - `pointnet2_part_seg_ssg.py`: PointNet++ part segmentation model with single-scale grouping\n",
    "  - `pointnet2_sem_seg_msg.py`: PointNet++ semantic segmentation model with multi-scale grouping\n",
    "  - `pointnet2_sem_seg_ssg.py`: PointNet++ semantic segmentation model with single-scale grouping\n",
    "  - `pointnet2_utils.py`: PointNet++ util functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import train_classification\n",
    "import test_classification\n",
    "\n",
    "import train_partseg\n",
    "import test_partseg\n",
    "\n",
    "import train_semseg\n",
    "import test_semseg\n",
    "\n",
    "# import torch\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 23 11:48:03 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.70                 Driver Version: 560.70         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   42C    P8              6W /  220W |    1663MiB /  12282MiB |     17%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2568    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A      2644    C+G   ...5n1h2txyewy\\AccountsControlHost.exe      N/A      |\n",
      "|    0   N/A  N/A      4240    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      6900    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      8304    C+G   ...es\\Firefox Package Root\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A      9660    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A      9700    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A      9724    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     10708    C+G   ...ft Office\\root\\Office16\\WINWORD.EXE      N/A      |\n",
      "|    0   N/A  N/A     10900    C+G   ...e Stream\\95.0.2.0\\GoogleDriveFS.exe      N/A      |\n",
      "|    0   N/A  N/A     11672    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     11996    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12620    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14276    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     14836    C+G   ...on\\128.0.2739.42\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     15368    C+G   ...yewy\\Microsoft.AAD.BrokerPlugin.exe      N/A      |\n",
      "|    0   N/A  N/A     16440    C+G   ...t Office\\root\\Office16\\POWERPNT.EXE      N/A      |\n",
      "|    0   N/A  N/A     19156    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     22284    C+G   ...es\\Firefox Package Root\\firefox.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Optional**: External Directory\n",
    "\n",
    "If you want to put the log and data directories in a different location, you can use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_log_dir = str(Path('../log').resolve())\n",
    "data_dir = str(Path('../data').resolve())\n",
    "class_data_dir = str(Path(data_dir, 'modelnet40_normal_resampled').resolve())\n",
    "partseg_data_dir = str(Path(data_dir, 'shapenetcore_partanno_segmentation_benchmark_v0_normal').resolve())\n",
    "\n",
    "root_log_dir, data_dir, class_data_dir, partseg_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Classification (ModelNet)\n",
    "\n",
    "- ModelNet40 dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "#### **INPUT**\n",
    "\n",
    "Default `--data_dir` is `'data/modelnet40_normal_resampled'`.\n",
    "\n",
    "\n",
    "#### **OUTPUT**\n",
    "\n",
    "- TRAINING: `<log_root>/classification/<args.log_dir or TIME>/checkpoints/best_model.pth`\n",
    "- PREDICTION: `None (only prints accuracy)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_classification.py` is used to train the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: training [-h] [--use_cpu] [--gpu GPU] [--batch_size BATCH_SIZE]\n",
      "                [--model MODEL] [--num_category {10,40}] [--epoch EPOCH]\n",
      "                [--learning_rate LEARNING_RATE] [--num_point NUM_POINT]\n",
      "                [--optimizer OPTIMIZER] [--log_root LOG_ROOT]\n",
      "                [--log_dir LOG_DIR] [--decay_rate DECAY_RATE] [--use_normals]\n",
      "                [--process_data] [--use_uniform_sample] [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --use_cpu             use cpu mode\n",
      "  --gpu GPU             specify gpu device\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size in training\n",
      "  --model MODEL         model name [default: pointnet_cls]\n",
      "  --num_category {10,40}\n",
      "                        training on ModelNet10/40\n",
      "  --epoch EPOCH         number of epoch in training\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        learning rate in training\n",
      "  --num_point NUM_POINT\n",
      "                        Point Number\n",
      "  --optimizer OPTIMIZER\n",
      "                        optimizer for training\n",
      "  --log_root LOG_ROOT   log directory root [default: log]\n",
      "  --log_dir LOG_DIR     experiment root within log directory\n",
      "  --decay_rate DECAY_RATE\n",
      "                        decay rate\n",
      "  --use_normals         use normals\n",
      "  --process_data        save data offline\n",
      "  --use_uniform_sample  use uniform sampiling\n",
      "  --data_dir DATA_DIR   data directory [default:\n",
      "                        data/modelnet40_normal_resampled]\n"
     ]
    }
   ],
   "source": [
    "!python train_classification.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python train_classification.py --model pointnet2_cls_ssg --log_dir pointnet2_cls_ssg # --log_root ../log --data_dir ../data/modelnet40_normal_resampled\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ...\n",
      "CommandLineArgs(model='pointnet2_cls_ssg', log_dir='pointnet2_cls_ssg', log_root=WindowsPath('../log'), data_dir=WindowsPath('../data/modelnet40_normal_resampled'), use_cpu=False, gpu='0', batch_size=25, num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='adam', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)\n",
      "Load dataset ...\n",
      "The size of train data is 9843\n",
      "The size of test data is 2468\n",
      "No existing model, starting training from scratch...\n",
      "Epoch 1 (1/200):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [01:26<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Instance Accuracy: 0.679796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:20<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Instance Accuracy: 0.819596, Class Accuracy: 0.709704\n",
      "Best Instance Accuracy: 0.819596, Class Accuracy: 0.709704\n",
      "Saving at ..\\log\\classification\\pointnet2_cls_ssg\\checkpoints/best_model.pth\n",
      "Epoch 2 (2/200):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [01:24<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Instance Accuracy: 0.804885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:19<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Instance Accuracy: 0.868305, Class Accuracy: 0.811794\n",
      "Best Instance Accuracy: 0.868305, Class Accuracy: 0.811794\n",
      "Saving at ..\\log\\classification\\pointnet2_cls_ssg\\checkpoints/best_model.pth\n",
      "Epoch 3 (3/200):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m   : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpointnet2_cls_ssg\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_dir\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpointnet2_cls_ssg\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_root\u001b[39m\u001b[38;5;124m'\u001b[39m: root_log_dir,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m'\u001b[39m: class_data_dir,\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      8\u001b[0m classification_train_args \u001b[38;5;241m=\u001b[39m train_classification\u001b[38;5;241m.\u001b[39mCommandLineArgs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain_classification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassification_train_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\Documents\\pointnet-cleanup\\Pointnet_Pointnet2_pytorch\\train_classification.py:210\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    207\u001b[0m classifier \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    209\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _batch_id, (points, target) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(trainDataLoader, \u001b[38;5;241m0\u001b[39m), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(trainDataLoader), smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m):\n\u001b[0;32m    211\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    213\u001b[0m     points \u001b[38;5;241m=\u001b[39m points\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\.virtualenvs\\paprika311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\.virtualenvs\\paprika311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kuwaharah436\\.virtualenvs\\paprika311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# user defined arguments for command line as a dictionary\n",
    "args = {\n",
    "    'model'   : 'pointnet2_cls_ssg',\n",
    "    'log_dir' : 'pointnet2_cls_ssg',\n",
    "    # 'log_root': root_log_dir,\n",
    "    # 'data_dir': class_data_dir,\n",
    "}\n",
    "classification_train_args = train_classification.CommandLineArgs(**args)\n",
    "train_classification.main(classification_train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "`test_classification.py` is used to test the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Testing [-h] [--use_cpu] [--gpu GPU] [--batch_size BATCH_SIZE]\n",
      "               [--num_category {10,40}] [--num_point NUM_POINT]\n",
      "               [--log_root LOG_ROOT] --log_dir LOG_DIR [--use_normals]\n",
      "               [--use_uniform_sample] [--num_votes NUM_VOTES]\n",
      "               [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --use_cpu             use cpu mode\n",
      "  --gpu GPU             specify gpu device\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size in training\n",
      "  --num_category {10,40}\n",
      "                        training on ModelNet10/40\n",
      "  --num_point NUM_POINT\n",
      "                        Point Number\n",
      "  --log_root LOG_ROOT   Log directory root [default: log]\n",
      "  --log_dir LOG_DIR     Experiment root within log directory\n",
      "  --use_normals         use normals\n",
      "  --use_uniform_sample  use uniform sampiling\n",
      "  --num_votes NUM_VOTES\n",
      "                        Aggregate classification scores with voting\n",
      "  --data_dir DATA_DIR   data directory [default:\n",
      "                        data/modelnet40_normal_resampled]\n"
     ]
    }
   ],
   "source": [
    "!python test_classification.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python test_classification.py --log_dir pointnet2_cls_ssg # --log_root ../log --data_dir ../data/modelnet40_normal_resampled\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ...\n",
      "CommandLineArgs(log_dir='pointnet2_cls_ssg', log_root='C:\\\\Users\\\\kuwaharah436\\\\Documents\\\\pointnet-cleanup\\\\log', data_dir='C:\\\\Users\\\\kuwaharah436\\\\Documents\\\\pointnet-cleanup\\\\data\\\\modelnet40_normal_resampled', use_cpu=False, gpu='0', batch_size=24, num_category=40, num_point=1024, use_normals=False, use_uniform_sample=False, num_votes=3)\n",
      "Load dataset ...\n",
      "The size of test data is 2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:57<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Instance Accuracy: 0.868366, Class Accuracy: 0.807433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'log_dir': 'pointnet2_cls_ssg',\n",
    "    # 'log_root': root_log_dir,\n",
    "    # 'data_dir': class_data_dir,\n",
    "}\n",
    "classification_test_args = test_classification.CommandLineArgs(**args)\n",
    "test_classification.main(classification_test_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part Segmentation (ShapeNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "#### **INPUT**\n",
    "\n",
    "Default `--data_dir` is `'data/shapenetcore_partanno_segmentation_benchmark_v0_normal'`.\n",
    "\n",
    "From `data/shapenetcore_partanno_segmentation_benchmark_v0_normal/synsetoffset2category.txt`, the folders correspond to the following categories:\n",
    "\n",
    "- `Airplane`: 02691156\n",
    "- `Bag`: 02773838\n",
    "- `Cap`: 02954340\n",
    "- `Car`: 02958343\n",
    "- `Chair`: 03001627\n",
    "- `Earphone`: 03261776\n",
    "- `Guitar`: 03467517\n",
    "- `Knife`: 03624134\n",
    "- `Lamp`: 03636649\n",
    "- `Laptop`: 03642806\n",
    "- `Motorbike`: 03790512\n",
    "- `Mug`: 03797390\n",
    "- `Pistol`: 03948459\n",
    "- `Rocket`: 04099429\n",
    "- `Skateboard`: 04225987\n",
    "- `Table`: 04379243\n",
    "\n",
    "For each .txt file within the folder above, \n",
    "\n",
    " - `[i, :]` is the i th point.\n",
    " - `[:, 0:3]` is xyz.\n",
    " - `[:, 3:6]` is normalized xyz.\n",
    " - `[:, 6]` is the segmentation label.\n",
    "\n",
    "i.e., each row is a point, and the columns are `[x, y, z, nx, ny, nz, label]`.\n",
    "\n",
    "`--normal` flag will use all x-y-z-nx-ny-nz + label as input. Otherwise, only x-y-z + label will be used.\n",
    "\n",
    "#### **OUTPUT**\n",
    "\n",
    "- TRAINING: `<log_root>/part_seg/<args.log_dir or TIME>/checkpoints/best_model.pth`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Segmentation Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shapenet part segmentation\n",
    "seg_classes = {\n",
    "    'Earphone': [16, 17, 18],\n",
    "    'Motorbike': [30, 31, 32, 33, 34, 35],\n",
    "    'Rocket': [41, 42, 43],\n",
    "    'Car': [8, 9, 10, 11],\n",
    "    'Laptop': [28, 29],\n",
    "    'Cap': [6, 7],\n",
    "    'Skateboard': [44, 45, 46],\n",
    "    'Mug': [36, 37],\n",
    "    'Guitar': [19, 20, 21],\n",
    "    'Bag': [4, 5],\n",
    "    'Lamp': [24, 25, 26, 27],\n",
    "    'Table': [47, 48, 49],\n",
    "    'Airplane': [0, 1, 2, 3],\n",
    "    'Pistol': [38, 39, 40],\n",
    "    'Chair': [12, 13, 14, 15],\n",
    "    'Knife': [22, 23]\n",
    "}\n",
    "\n",
    "seg_ids = [seg_id for seg_val_sublist in seg_classes.values() for seg_id in seg_val_sublist]\n",
    "len(seg_classes), len(seg_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "`train_partseg.py` is used to train the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Model [-h] [--model MODEL] [--batch_size BATCH_SIZE] [--epoch EPOCH]\n",
      "             [--learning_rate LEARNING_RATE] [--gpu GPU]\n",
      "             [--optimizer OPTIMIZER] [--log_root LOG_ROOT] [--log_dir LOG_DIR]\n",
      "             [--decay_rate DECAY_RATE] [--npoint NPOINT] [--normal]\n",
      "             [--step_size STEP_SIZE] [--lr_decay LR_DECAY]\n",
      "             [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model MODEL         model name [default: pointnet_part_seg]\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch Size during training [default: 16]\n",
      "  --epoch EPOCH         epoch to run [default: 251]\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        initial learning rate [default: 0.001]\n",
      "  --gpu GPU             specify GPU devices [default: 0]\n",
      "  --optimizer OPTIMIZER\n",
      "                        Adam or SGD [default: Adam]\n",
      "  --log_root LOG_ROOT   Log root directory [default: log]\n",
      "  --log_dir LOG_DIR     log path wihin log root directory\n",
      "  --decay_rate DECAY_RATE\n",
      "                        weight decay [default: 1e-4]\n",
      "  --npoint NPOINT       point Number [default: 2048]\n",
      "  --normal              use normals\n",
      "  --step_size STEP_SIZE\n",
      "                        decay step for lr decay [default: 20]\n",
      "  --lr_decay LR_DECAY   decay rate for lr decay [default: 0.5]\n",
      "  --data_dir DATA_DIR   data directory [default: data/shapenetcore_partanno_se\n",
      "                        gmentation_benchmark_v0_normal]\n"
     ]
    }
   ],
   "source": [
    "!python train_partseg.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python train_partseg.py --model pointnet2_part_seg_msg --normal --log_dir pointnet2_part_seg_msg # --log_root ../log --data_dir ../data/shapenetcore_partanno_segmentation_benchmark_v0_normal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ...\n",
      "CommandLineArgs(model='pointnet2_part_seg_msg', normal=True, log_dir='pointnet2_part_seg_msg', log_root='C:\\\\Users\\\\kuwaharah436\\\\Documents\\\\pointnet-cleanup\\\\log', data_dir='C:\\\\Users\\\\kuwaharah436\\\\Documents\\\\pointnet-cleanup\\\\data\\\\shapenetcore_partanno_segmentation_benchmark_v0_normal', batch_size=16, epoch=251, learning_rate=0.001, gpu='0', optimizer='Adam', decay_rate=0.0001, npoint=2048, step_size=20, lr_decay=0.5)\n",
      "The number of training data is: 13998\n",
      "The number of test data is: 2874\n",
      "Use pretrain model\n",
      "Epoch 1 (106/251):\n",
      "Learning rate:0.000031\n",
      "BN momentum updated to: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 874/874 [05:11<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is: 0.95614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:48<00:00,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mIoU of Airplane       0.825307\n",
      "eval mIoU of Bag            0.824338\n",
      "eval mIoU of Cap            0.859586\n",
      "eval mIoU of Car            0.781119\n",
      "eval mIoU of Chair          0.904227\n",
      "eval mIoU of Earphone       0.721575\n",
      "eval mIoU of Guitar         0.910299\n",
      "eval mIoU of Knife          0.873144\n",
      "eval mIoU of Lamp           0.850496\n",
      "eval mIoU of Laptop         0.955203\n",
      "eval mIoU of Motorbike      0.717333\n",
      "eval mIoU of Mug            0.950542\n",
      "eval mIoU of Pistol         0.834041\n",
      "eval mIoU of Rocket         0.601368\n",
      "eval mIoU of Skateboard     0.767600\n",
      "eval mIoU of Table          0.822660\n",
      "Epoch 106 test Accuracy: 0.942837  Class avg mIOU: 0.824927   Inctance avg mIOU: 0.851658\n",
      "Saving at C:\\Users\\kuwaharah436\\Documents\\pointnet-cleanup\\log\\part_seg\\pointnet2_part_seg_msg\\checkpoints/best_model.pth\n",
      "Saving model....\n",
      "Best accuracy is: 0.94284\n",
      "Best class avg mIOU is: 0.82493\n",
      "Best inctance avg mIOU is: 0.85166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9428369446437892,\n",
       " 'class_avg_accuracy': 0.8736334371089879,\n",
       " 'class_avg_iou': 0.8249273205648262,\n",
       " 'inctance_avg_iou': 0.8516575181521382}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {\n",
    "    'model'   : 'pointnet2_part_seg_msg',\n",
    "    'normal'  : True, # in source: action='store_true'\n",
    "    'log_dir' : 'pointnet2_part_seg_msg',\n",
    "    # 'log_root': root_log_dir,\n",
    "    # 'data_dir': partseg_data_dir,\n",
    "}\n",
    "partseg_train_args = train_partseg.CommandLineArgs(**args)\n",
    "train_partseg.main(partseg_train_args, seg_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "`test_partseg.py` is used to test the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: PointNet [-h] [--batch_size BATCH_SIZE] [--gpu GPU]\n",
      "                [--num_point NUM_POINT] [--log_root LOG_ROOT] --log_dir\n",
      "                LOG_DIR [--normal] [--num_votes NUM_VOTES]\n",
      "                [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size in testing\n",
      "  --gpu GPU             specify gpu device\n",
      "  --num_point NUM_POINT\n",
      "                        point Number\n",
      "  --log_root LOG_ROOT   Log directory root\n",
      "  --log_dir LOG_DIR     experiment root within log directory\n",
      "  --normal              use normals\n",
      "  --num_votes NUM_VOTES\n",
      "                        aggregate segmentation scores with voting\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python test_partseg.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python test_partseg.py --normal --log_dir pointnet2_part_seg_msg # --log_root ../log --data_dir ../data/shapenetcore_partanno_segmentation_benchmark_v0_normal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ...\n",
      "CommandLineArgs(normal=True, log_dir='pointnet2_part_seg_msg', log_root='C:\\\\Users\\\\kuwaharah436\\\\Documents\\\\pointnet-cleanup\\\\log', data_dir='C:\\\\Users\\\\kuwaharah436\\\\Documents\\\\pointnet-cleanup\\\\data\\\\shapenetcore_partanno_segmentation_benchmark_v0_normal', batch_size=24, gpu='0', num_point=2048, num_votes=3)\n",
      "The number of test data is: 2874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:01<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mIoU of Airplane       0.830213\n",
      "eval mIoU of Bag            0.833720\n",
      "eval mIoU of Cap            0.871498\n",
      "eval mIoU of Car            0.778895\n",
      "eval mIoU of Chair          0.905875\n",
      "eval mIoU of Earphone       0.712962\n",
      "eval mIoU of Guitar         0.911574\n",
      "eval mIoU of Knife          0.869566\n",
      "eval mIoU of Lamp           0.851985\n",
      "eval mIoU of Laptop         0.955406\n",
      "eval mIoU of Motorbike      0.721616\n",
      "eval mIoU of Mug            0.953034\n",
      "eval mIoU of Pistol         0.825773\n",
      "eval mIoU of Rocket         0.610564\n",
      "eval mIoU of Skateboard     0.768345\n",
      "eval mIoU of Table          0.830707\n",
      "Accuracy is: 0.94423\n",
      "Class avg accuracy is: 0.87298\n",
      "Class avg mIOU is: 0.82698\n",
      "Inctance avg mIOU is: 0.85510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'normal'  : True, # in source: action='store_true'\n",
    "    'log_dir' : 'pointnet2_part_seg_msg',\n",
    "    'log_root': root_log_dir,\n",
    "    'data_dir': partseg_data_dir,\n",
    "}\n",
    "partseg_test_args = test_partseg.CommandLineArgs(**args)\n",
    "test_metrics, shape_ious, total_correct_class, total_seen_class = test_partseg.main(partseg_test_args, seg_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.944225335170929,\n",
       "  'class_avg_accuracy': 0.8729847674087255,\n",
       "  'class_avg_iou': 0.8269832436731457,\n",
       "  'inctance_avg_iou': 0.8550982761395242},\n",
       " {'Earphone': 0.7129622178618391,\n",
       "  'Motorbike': 0.7216161809824075,\n",
       "  'Rocket': 0.6105638185383957,\n",
       "  'Car': 0.7788951500254214,\n",
       "  'Laptop': 0.9554060803508303,\n",
       "  'Cap': 0.8714980462658769,\n",
       "  'Skateboard': 0.7683450655494334,\n",
       "  'Mug': 0.9530338720707381,\n",
       "  'Guitar': 0.9115735365391211,\n",
       "  'Bag': 0.8337195079879579,\n",
       "  'Lamp': 0.851985120236742,\n",
       "  'Table': 0.8307068789292265,\n",
       "  'Airplane': 0.8302130795435185,\n",
       "  'Pistol': 0.8257730856157082,\n",
       "  'Chair': 0.9058747480369523,\n",
       "  'Knife': 0.8695655102361629})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics, shape_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Airplane': {0: 0.9456879956097434,\n",
      "              1: 0.916028658386737,\n",
      "              2: 0.8438012489818083,\n",
      "              3: 0.8907710048113245},\n",
      " 'Bag': {4: 0.6681193429433456, 5: 0.9960294289384561},\n",
      " 'Cap': {6: 0.9896882203081402, 7: 0.7613373055279709},\n",
      " 'Car': {8: 0.8615010959066406,\n",
      "         9: 0.7923612022575142,\n",
      "         10: 0.8433229928355123,\n",
      "         11: 0.9569071357046454},\n",
      " 'Chair': {12: 0.9639621398000587,\n",
      "           13: 0.9567408163020801,\n",
      "           14: 0.934777435434984,\n",
      "           15: 0.846165024558956},\n",
      " 'Earphone': {16: 0.9518459069020867,\n",
      "              17: 0.953810623556582,\n",
      "              18: 0.2647272727272727},\n",
      " 'Guitar': {19: 0.9503452811575139,\n",
      "            20: 0.9030249231819734,\n",
      "            21: 0.9874232534673892},\n",
      " 'Knife': {22: 0.8991684246676152, 23: 0.9662365748165428},\n",
      " 'Lamp': {24: 0.9089753178758414,\n",
      "          25: 0.9564545662623026,\n",
      "          26: 0.9634393063583815,\n",
      "          27: 0.8362064590346975},\n",
      " 'Laptop': {28: 0.9853675480873605, 29: 0.9738633444644234},\n",
      " 'Motorbike': {30: 0.7826520438683948,\n",
      "               31: 0.7906595657517411,\n",
      "               32: 0.8064250788283143,\n",
      "               33: 0.6724303554274735,\n",
      "               34: 0.7615023474178404,\n",
      "               35: 0.914278068087384},\n",
      " 'Mug': {36: 0.9300733496332518, 37: 0.9989014565871918},\n",
      " 'Pistol': {38: 0.9807475974672967,\n",
      "            39: 0.9328367903693761,\n",
      "            40: 0.7765491341539745},\n",
      " 'Rocket': {41: 0.9303144203806456,\n",
      "            42: 0.658672294704528,\n",
      "            43: 0.6219746446407991},\n",
      " 'Skateboard': {44: 0.8762028608582575,\n",
      "                45: 0.9813872854394087,\n",
      "                46: 0.8167523435137587},\n",
      " 'Table': {47: 0.9774806815609945,\n",
      "           48: 0.9329050834575696,\n",
      "           49: 0.8384031174201757}}\n"
     ]
    }
   ],
   "source": [
    "seg_correct = dict(zip(range(len(seg_ids)), total_correct_class))\n",
    "seg_total = dict(zip(range(len(seg_ids)), total_seen_class))\n",
    "\n",
    "seg_acc = {}\n",
    "for id, correct_n in seg_correct.items():\n",
    "    total_n = seg_total[id]\n",
    "    if total_n == 0:\n",
    "        seg_acc[id] = 0\n",
    "    else:\n",
    "        seg_acc[id] = correct_n / total_n\n",
    "# print(seg_acc)\n",
    "\n",
    "seg_class_acc = {}\n",
    "for cat in seg_classes:\n",
    "    seg_class_acc[cat] = {}\n",
    "    for id in seg_classes[cat]:\n",
    "        seg_class_acc[cat][id] = seg_acc[id]\n",
    "\n",
    "pprint(seg_class_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Semantic Segmentation (S3DIS): **UNTESTED**\n",
    "\n",
    "**UNTESTED**: Unfortunately, the S3DIS dataset is not available as of Aug. 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "`train_semseg.py` is used to train the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Model [-h] [--model MODEL] [--batch_size BATCH_SIZE] [--epoch EPOCH]\n",
      "             [--learning_rate LEARNING_RATE] [--gpu GPU]\n",
      "             [--optimizer OPTIMIZER] [--log_dir LOG_DIR]\n",
      "             [--decay_rate DECAY_RATE] [--npoint NPOINT]\n",
      "             [--step_size STEP_SIZE] [--lr_decay LR_DECAY]\n",
      "             [--test_area TEST_AREA] [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model MODEL         model name [default: pointnet_sem_seg]\n",
      "  --batch_size BATCH_SIZE\n",
      "                        Batch Size during training [default: 16]\n",
      "  --epoch EPOCH         Epoch to run [default: 32]\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        Initial learning rate [default: 0.001]\n",
      "  --gpu GPU             GPU to use [default: GPU 0]\n",
      "  --optimizer OPTIMIZER\n",
      "                        Adam or SGD [default: Adam]\n",
      "  --log_dir LOG_DIR     Log path [default: None]\n",
      "  --decay_rate DECAY_RATE\n",
      "                        weight decay [default: 1e-4]\n",
      "  --npoint NPOINT       Point Number [default: 4096]\n",
      "  --step_size STEP_SIZE\n",
      "                        Decay step for lr decay [default: every 10 epochs]\n",
      "  --lr_decay LR_DECAY   Decay rate for lr decay [default: 0.7]\n",
      "  --test_area TEST_AREA\n",
      "                        Which area to use for test, option: 1-6 [default: 5]\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python train_semseg.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python train_semseg.py --model pointnet2_sem_seg --test_area 5 --log_dir pointnet2_sem_seg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'model'    : 'pointnet2_sem_seg',\n",
    "    'test_area': 5,\n",
    "    'log_dir'  : 'pointnet2_sem_seg'\n",
    "}\n",
    "semseg_train_args = train_semseg.CommandLineArgs(**args)\n",
    "train_semseg.main(semseg_train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "`test_semseg.py` is used to test the model.\n",
    "\n",
    "Check all the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Model [-h] [--batch_size BATCH_SIZE] [--gpu GPU]\n",
      "             [--num_point NUM_POINT] --log_dir LOG_DIR [--visual]\n",
      "             [--test_area TEST_AREA] [--num_votes NUM_VOTES]\n",
      "             [--data_dir DATA_DIR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --batch_size BATCH_SIZE\n",
      "                        batch size in testing [default: 32]\n",
      "  --gpu GPU             specify gpu device\n",
      "  --num_point NUM_POINT\n",
      "                        point number [default: 4096]\n",
      "  --log_dir LOG_DIR     experiment root\n",
      "  --visual              visualize result [default: False]\n",
      "  --test_area TEST_AREA\n",
      "                        area for testing, option: 1-6 [default: 5]\n",
      "  --num_votes NUM_VOTES\n",
      "                        aggregate segmentation scores with voting [default: 5]\n",
      "  --data_dir DATA_DIR   data directory\n"
     ]
    }
   ],
   "source": [
    "!python test_semseg.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same as running:\n",
    "\n",
    "```shell\n",
    "python test_semseg.py --log_dir pointnet2_sem_seg --test_area 5 --visual\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'log_dir'  : 'pointnet2_sem_seg',\n",
    "    'test_area': 5,\n",
    "    'visual'   : True, # in source: action='store_true'\n",
    "}\n",
    "semseg_test_args = test_semseg.CommandLineArgs(**args)\n",
    "test_semseg.main(semseg_test_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paprika311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
